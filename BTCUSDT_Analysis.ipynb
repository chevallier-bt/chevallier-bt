{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BTCUSDT Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "toc_visible": true,
      "mount_file_id": "1FC2DWuY0QUu-Z7nAbFUMLiEUblqOChOK",
      "authorship_tag": "ABX9TyNGd8ka8IazxcjZW55K4wJa"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#<center>BTC/USDT Analysis</center>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_GHABHwmIb3f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recurrent Deep Learning Approach\n"
      ],
      "metadata": {
        "id": "-tbCX57uPDlQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Pre Discussion\n",
        "\n",
        "If nothing else, I urge the reader to read the summary section just after section 1.7. There I briefly discuss the main components of this approach, as well as where I believe the sources of failure are located.\n",
        "\n",
        "### Time scale\n",
        "I believe that when dealing with large timescales (1h, 4h, 1d, ...) crypto analysis is best done by humans considering real world data, such as political activity, public sentiment, etc., which I'll call \"macro variables\". However, as smaller timescales are used, there is a tradeoff between the macro-variables and micro-variables. I believe the micro-variables are more predictable using purely numerical methods, though with each smaller timescale there is a stronger element of randomness. It will be important to find the right balance between these three influences.\n",
        "\n",
        "---\n",
        "\n",
        "### Data sampling\n",
        "This comes with its own set of challenges, the first which comes to mind and will need to be addressed is the sampling of the data. Fundamentally, RNNs require the data to be ordered, and use the timestamp of the data to remember certain patterns for further use. I will make sure to not shuffle the data at any point.\n",
        "\n",
        "---\n",
        "\n",
        "### Data Labelling\n",
        "The data will be labelled using the grader function from my previous attempts. This will be discussed below, so don't worry. At this point, this is still the best option I have with my knowledge, and so I will continue to use it.\n",
        "\n",
        "---\n",
        "\n",
        "### Data formatting\n",
        "For the prototyping phase, I will severely shorten the data set so that computations can be done quickly. Once the overall model structure is built, I will use the full dataset. One consideration for data formatting is that the data will need to be trimmed on both ends, depending on:\n",
        "* The length of indicators used (such as moving averages, standard deviation): For example, a 20-pt moving average will need at least 20 data points prior to be properly calculated. If 20-pt was the largest used in the data, then the oldest 20 data points would need to be removed after the MA is calculated.\n",
        "* The 'n' parameter of the grader function: If the algorithm is trained based on labels that look 40 data points into the future to evaluate the success of a trade, then the most recent 40 data points will need to be removed after the grader function is applied.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### LSTM Discussion\n",
        "\n",
        "The grunt work setting up the data prep functions to be iterated over several times is now mostly complete, I need to start considering how this data will be parsed through to the RNN. It would seem that the LSTM layer is the golden child of RNN layers, and so that is what I will be using.\n",
        "\n",
        "My initial reading shows that the fundamental difference between LSTM input data and regular input data is the LSTM now takes a rank 3 tensor with shape (batches, timestamps, features). This was very confusing at first, but after reading through the [TensorFlow Windowing section](https://www.tensorflow.org/tutorials/structured_data/time_series#data_windowing), I believe I understand.\n",
        "\n",
        "Since I am predicting whether or not the current data point is a good long trade or short trade, I can specify immediately that the label width is 1, with 0 shift. For example, for a window length of 5 inputs, the data input for the LSTM layer might look like:\n",
        "\n",
        "\\begin{align}\n",
        "    \\text{df} = \\begin{bmatrix} d_0 & d_1 & d_2 & d_3 & d_4\\\\\n",
        "                                    d_1 & d_2 & d_3 & d_4 & d_5 \\\\\n",
        "                                    \\vdots & \\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
        "                                    d_{n-4} & d_{n-3} & d_{n-2} & d_{n-1} &d_n          \n",
        "    \\end{bmatrix}\n",
        "\\end{align}\n",
        "\n",
        "Where df is our dataframe, each row represents one batch of data, and each of $d_i$ are themselves an array containing the features of our data (high, open, close, sma-20, sd-20, buy, sell, etc..). In this example, the last element of each batch would be used to determine the labels for that batch. Let's define some variables:\n",
        "\n",
        "\\begin{align}\n",
        "    W &: \\text{Window length}\\\\\n",
        "    N &: \\text{Number of data points}\\\\\n",
        "    B &: \\text{Number of batches}\\\\\n",
        "    F &: \\text{Number of features}\n",
        "\\end{align}\n",
        "\n",
        "Then it would be nice to know the relationship between $B$, $N$, and $W$ for writing my data prep function. Using the frame df above, I can see that the final index of the first row is equal to our window length (using standard upper bound exclusion). There will be $n-5$ batches in df above, or, converting to our variables:\n",
        "$$B = N-W$$\n",
        "\n",
        "\n",
        "So, when constructing our tensor with window length specified, the frame dimensions should be\n",
        "$$\\text{shape} = (N-W,\\;\\;W,\\;\\;F)$$\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "si1GOBDLxzTJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Setup\n",
        "\n",
        "#### Imports"
      ],
      "metadata": {
        "id": "UkhsNE8ozDFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import copy\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, LSTM, Bidirectional\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "PkXo4Vdej8DV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sma(items, *args):\n",
        "    \"\"\"\n",
        "    get_sma() function will return the simple moving average for the list \"items\" with period \"n\".\n",
        "    Use of args here is redundant, but I was planning on adding more to this function later.\n",
        "    \"\"\"\n",
        "    items = copy.copy(items)\n",
        "    n = args[0]\n",
        "    return items.rolling(n).mean()\n",
        "\n",
        "def get_sd(items, *args):\n",
        "    \"\"\"\n",
        "    get_sd() function will return the standard deviation for the list \"items\" with period \"n\".\n",
        "    Use of args here is redundant, but I was planning on adding more to this function later.\n",
        "    \"\"\"\n",
        "    items = copy.copy(items)\n",
        "    n = args[0]\n",
        "    return items.rolling(n).std()\n",
        "\n",
        "def normalize(df):\n",
        "    return (df-df.min())/(df.max()-df.min())\n",
        "\n",
        "raw = pd.read_csv(\"/content/drive/MyDrive/Machine Learning/BTCUSDT Analysis/binance_BTCUSDT_minute.csv\", low_memory=False, sep=\",\", header = 1)\n",
        "print(raw.columns)"
      ],
      "metadata": {
        "id": "ZAxt6yCguxjJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecce667d-21b3-4c85-d721-1481e836158c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['unix', 'date', 'symbol', 'open', 'high', 'low', 'close', 'Volume BTC',\n",
            "       'Volume USDT', 'tradecount'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3 The Grader and DataPrep functions\n",
        "\n",
        "The cornerstone of this approach is the grader function in the code block below. This is a compromise to label the data, since ideally the algorithm would be able to place both long and short orders, as well as vary the amount placed on each trade. However, I do not know of a way to allow the network to calculate the true value of a label during the training, as would be required for such a flexible algorithm.\n",
        "\n",
        "Instead, I train the algorithm to always place long trades with specified stop-loss (SL) and take-profit (TP) levels. These levels are decided based on the following variables:\n",
        "\n",
        "*    Reward/risk ratio: The reward to risk ratio is the ratio of potential profit to the potential loss.\n",
        "*    Profit level: The desired TP level for the trade, in terms of percentage increase.\n",
        "\n",
        "Both the reward to risk ratio and the profit level need to be specified to the grader function. The last missing piece is the amount of data points to check for the specified TP/SL levels. Of course, I could let the algorithm go on forever until either the TP or SL is triggered, but since the algorithm is designed to work on short timescales, I should limit the grader function to work in this scope.\n",
        "\n",
        "With all these variables, the grader function executes as follows. Given the arguments:\n",
        "* df     : A dataframe of shape (1,X) with all the closing prices is sent to the function.\n",
        "* profit : The desired profit percentage on the trade\n",
        "* rr     :The desired reward to risk ratio\n",
        "* n      :The amount of data points to check\n",
        "\n",
        "For every data point in 'df', the function will iterate over the next 'n' data points immediately following the current data point d[i]. If at any point d[i] exceeds the TP level (1+profit) or falls below the SL level (1-$profit/rr) then the current loop iteration will break and return 1 or 0. A 1 corresponds to a successful trade, and a 0 represents a failed trade."
      ],
      "metadata": {
        "id": "yPNdaKJl_Fmo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def grader(df, type, *args):\n",
        "    \"\"\"\n",
        "    Grader function, takes a pd DataFrame 'df' as input and outputs whether or not a buy (long trade) or\n",
        "        a sell (short trade) at the current data point would trigger a stop loss or a take profit within\n",
        "        'n_tries' data points at a reward/risk ratio and profit level of 'rr' and 'profit', respectively.\n",
        "        df      :  pandas DataFrame with shape (1,x)\n",
        "        type    :  String, \"long\" or \"short\" to indicate trade type\n",
        "        profit  :  Number, The desired profit, in percentage form\n",
        "        rr      :  Number, The reward/risk ratio, used to calculate stop-loss and take-profit\n",
        "        n_tries :  Number, Number of data points to look into the future for the SL or TP\n",
        "\n",
        "        Use of *args here is to simplify parsing of data later on through the DataPrep function.\n",
        "    \"\"\"\n",
        "    # Unpack the args\n",
        "    args = list(args)\n",
        "    profit, rr, n_tries = args[0]\n",
        "\n",
        "    # Make sure I am not modifying the original DataFrame\n",
        "    df = copy.copy(df)\n",
        "\n",
        "    if type is \"long\":\n",
        "        sl = copy.copy(df) * (1-profit/rr)\n",
        "        tp = copy.copy(df) * (1+profit)\n",
        "\n",
        "        for i, close in enumerate(df):\n",
        "\n",
        "            if i==df.shape[0] - n_tries:\n",
        "                df.iloc[-n_tries:] = 0\n",
        "\n",
        "            for k in range(i, i+n_tries):\n",
        "                #SL Trigger\n",
        "                if close <= sl.iloc[k]:\n",
        "                    df.iloc[i] = 0\n",
        "                    break\n",
        "                #TP Trigger\n",
        "                elif close >= tp.iloc[k]:\n",
        "                    df.iloc[i] = 1\n",
        "                    break\n",
        "                df.iloc[i] = 0\n",
        "        \n",
        "\n",
        "        return df\n",
        "\n",
        "    # If the trade type is short, I are looking for a TP below the close, with a corresponding SL above the close\n",
        "    #     specified similarly by the profit and reward/risk ratio.\n",
        "    elif type is \"short\":\n",
        "        sl = copy.copy(df) * (1+profit/rr)\n",
        "        tp = copy.copy(df) * (1-profit)\n",
        "\n",
        "        for i, close in enumerate(df):\n",
        "\n",
        "            if i==df.shape[0] - n_tries:\n",
        "                df.iloc[-n_tries:] = 0\n",
        "\n",
        "            for k in range(i, i+n_tries):\n",
        "                #SL Trigger\n",
        "                if close >= sl.iloc[k]:\n",
        "                    df.iloc[i] = 0\n",
        "                    break\n",
        "                #TP Trigger\n",
        "                elif close <= tp.iloc[k]:\n",
        "                    df.iloc[i] = 1\n",
        "                    break\n",
        "                df.iloc[i] = 0\n",
        "            \n",
        "        return df\n",
        "\n",
        "    # The trade was not properly specified, so return None\n",
        "    return None"
      ],
      "metadata": {
        "id": "miHmHrWw_FHP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The DataPrep function is another large player in this approach. The idea is to have a single function which can be passed the raw data and output a completely formatted set of DataFrames which are ready to be passed to the LSTM layer. Here is the key functionality:\n",
        "\n",
        "\n",
        "* Remove any undesired columns from the raw data, through use of the 'remove' parameter. \n",
        "* Add any desired technical indicators, through the use of the 'indicator_dict' dictionary, which pairs keywords to the technical indicator functions defined above. This information is parsed through the 'indicators' argument.\n",
        "* Parameters for the grader function are passed through the 'grader_params' parameter, formatted as [profit, rr, n_tries]\n",
        "\n",
        "The rest is relatively simple to explain and is documented in the DataPrep function below:"
      ],
      "metadata": {
        "id": "4hCYSxbw3w6c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# As mentioned above, for the prototyping phase, only the a small sample will be used. I use a\n",
        "pData = raw.iloc[:10187]\n",
        "\n",
        "# Dictionary to parse the DataPrep function desired indicators to their respective functions\n",
        "#    for calculation.\n",
        "indicator_dict = {\n",
        "    \"sma\" : get_sma,\n",
        "    \"sd\" : get_sd\n",
        "}\n",
        "\n",
        "# DataFrame to hold any indicators that have already been calculated to optimize. All\n",
        "#    indicators are calculated prior to any splitting or shuffling of data. Thus, they \n",
        "#    are consistent across several data prep cycles.\n",
        "stored_indicators = pd.DataFrame();\n",
        "\n",
        "def DataPrep(df, \n",
        "             test_ratio = 0.2,\n",
        "             window_size = 10,\n",
        "             return_frame = False,\n",
        "             verbose = False,\n",
        "             grader_params = [0.001, 2, 30],\n",
        "             remove = [\"date\", \"symbol\", \"Volume BTC\", \"tradecount\"], \n",
        "             indicators = [(\"sma\", 20), (\"sd\", 20), (\"sma\", 10), (\"sd\", 10)]\n",
        "             ):\n",
        "    \"\"\"\n",
        "        Parameters\n",
        "    df            : Pandas DataFrame, The data set to prepare. Has known structure and layout.\n",
        "    test_ratio    : Number between 0 and 1, The ratio of test data to training data\n",
        "    window_size   : Number, the amount of data points per batch\n",
        "    return_frame  : Whether or not I return the non-LSTM-modified DataFrame (useful for debugging)\n",
        "    verbose       : Whether or not to print progress from the function call.\n",
        "    grader_params : List, The parameters to be sent to the grader function (profit, rr, n)\n",
        "    remove        : List, The columns to be removed\n",
        "    indicators    : List, The indicators to be added\n",
        "        Returns\n",
        "    batch_train   : Pandas DataFrame, The training rank-3 tensor to be used in the LSTM layer (batches, window, features)\n",
        "    batch_test    : Pandas DataFrame, The testing rank-3 tensor to be used in the LSTM layer (batches, window, features)\n",
        "    train_labels  : Pandas DataFrame, The labels for the training data\n",
        "    test_labels   : Pandas DataFrame, The labels for the testing data\n",
        "    df            : Pandas DataFrame, Optional, The non-windowed DataFrame (index, features)\n",
        "    \"\"\"\n",
        "\n",
        "    if verbose: print(\"Data prep start\")\n",
        "    # Define some variables to help trim later\n",
        "    max_period = 0\n",
        "    grader_period = grader_params[2]\n",
        "\n",
        "    # Indexing and bulk removal -- Want oldest data first so RNN reads along positive time direction\n",
        "    df = df[::-1]\n",
        "    # Index differential is used to ensure that the list did in fact get reversed\n",
        "    if verbose: print(\"...Indexing complete. Index differential: %i\" %(df[\"unix\"].iloc[1] - df[\"unix\"].iloc[0]))\n",
        "    df = df.drop(columns = remove)\n",
        "    if verbose: print(\"...Columns removed\")\n",
        "\n",
        "    # Any base renaming to be done\n",
        "    df[\"vol\"] = copy.copy(df[\"Volume USDT\"])\n",
        "    df = df.drop(\"Volume USDT\", axis=1)\n",
        "    if verbose: print(\"...Renaming complete\")\n",
        "\n",
        "    # Indicator calculator. For each tuple in \"indicators\", relevant information\n",
        "    #    is passed to add the desired indicator to the data set. If the indicator\n",
        "    #    has already been calculated and stored in the stored_indicators list,\n",
        "    #    it will pull from that instead of calulating it from scratch.\n",
        "    if verbose: print(\"...Starting indicators\")\n",
        "    for item in indicators:\n",
        "\n",
        "        #Identify the indicator and period\n",
        "        indicator, period = item\n",
        "        #Create the label \"indicator-period\"\n",
        "        label = indicator + \"-\" + str(period)\n",
        "        if verbose: print(\"      Indicator %s identified\" %label)\n",
        "\n",
        "        # I need to know the max period of the indicators to know how much data\n",
        "        #    to trim from the beginning of the data set. This is to avoid NaN in\n",
        "        #    our data.\n",
        "        if period > max_period:\n",
        "            max_period = period\n",
        "\n",
        "        # If I have already calculated this label and it is stored in our list:\n",
        "        if label in stored_indicators.columns:\n",
        "            if verbose: print(\"      Indicator found in stored list\")\n",
        "            df[label] = copy.copy(stored_indicators[label])\n",
        "        # If I have not yet calculated this label\n",
        "        else:\n",
        "            # Use the dictionary to calculate the desired indicator and store it in df\n",
        "            df[label] = indicator_dict[indicator](df[\"close\"], period)\n",
        "            # Also store the indicator in the stored list for further use\n",
        "            stored_indicators[label] = copy.copy(df[label])\n",
        "            if verbose: print(\"      New indicator %s added to list\" %label)\n",
        "\n",
        "    if verbose: print(\"...Indicators complete\")\n",
        "\n",
        "    if verbose: print(\"...Grader function called\")\n",
        "    # Calculate the labels for the data set using the grader_params provided\n",
        "    df[\"long\"] = grader(df[\"close\"], \"long\", grader_params)\n",
        "    if verbose: print(\"      Long trade labels complete\")\n",
        "    df[\"short\"] = grader(df[\"close\"], \"short\", grader_params)\n",
        "    if verbose: print(\"      Short trade labels complete\")\n",
        "    if verbose: print(\"...Grader function complete\")\n",
        "\n",
        "    \n",
        "\n",
        "    # Trim the data set based on the largest indicator period and the grader period\n",
        "    df = df.iloc[max_period : -1*grader_period]\n",
        "    if verbose: print(\"...Data trimmed\")\n",
        "\n",
        "    # Normalize all the data\n",
        "    for col in df.columns:\n",
        "        df[col] = normalize(df[col]) \n",
        "    if verbose: print(\"...Data normalized\") \n",
        "    \n",
        "\n",
        "\n",
        "    # Create the train and test splits for the data\n",
        "    train, test = train_test_split(df, test_size = test_ratio, shuffle=False)\n",
        "    train_labels = copy.copy(train[[\"long\", \"short\"]])\n",
        "    train = train.drop([\"long\", \"short\"], axis=1)\n",
        "    test_labels = copy.copy(test[[\"long\", \"short\"]])\n",
        "    test = test.drop([\"long\", \"short\"], axis=1)\n",
        "    if verbose: print(\"...Train-test split created\")\n",
        "\n",
        "    # Define some variables to be used during the tensor creation\n",
        "    train_batches = train.shape[0] - window_size\n",
        "    test_batches = test.shape[0] - window_size\n",
        "    num_features = train.shape[1]\n",
        "\n",
        "    # Create the tensor for use in the LSTM layer -- This is much more optimized in the \n",
        "    #     2nd iteration DataPrep function in section 1.6.2\n",
        "    if verbose: print(\"...Starting tensor creation\")\n",
        "    batch_train = np.empty(shape = (train_batches, window_size, num_features), dtype = np.float32)\n",
        "    batch_test = np.empty(shape = (test_batches, window_size, num_features), dtype = np.float32)\n",
        "\n",
        "    if verbose: print(\"      Train tensor with %i batches, %i window size\" %(train_batches, window_size))\n",
        "    for i in range(train_batches):\n",
        "        for v in range(window_size):\n",
        "            batch_train[i][v] = train.iloc[i + v]\n",
        "    if verbose: print(\"      Train tensor created with shape :\", batch_train.shape)\n",
        "\n",
        "    if verbose: print(\"      Test tensor with %i batches, %i window size\" %(test_batches, window_size))\n",
        "    for i in range(test_batches):\n",
        "        for v in range(window_size):\n",
        "            batch_test[i][v] = test.iloc[i + v]\n",
        "    if verbose: print(\"      Test tensor created with shape :\", batch_test.shape)\n",
        "    if verbose: print(\"...Tensor creation complete\")\n",
        "    if verbose: print(\"Data Prep Complete\")\n",
        "\n",
        "\n",
        "\n",
        "    if return_frame: return batch_train, batch_test, train_labels, test_labels, df\n",
        "\n",
        "    return batch_train, batch_test, train_labels[window_size:], test_labels[window_size:]"
      ],
      "metadata": {
        "id": "USUvDemX4KcQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pGraderParams = [0.001, 2, 50] # Aiming for a profit of 0.1%, reward/risk ratio of 2, and looking 50 ticks into the future\n",
        "pWindowSize = 30 # Want the timesteps window size to have a width of 30\n",
        "\n",
        "# Call the DataPrep function and get all our sets of data!\n",
        "pxTrain, pxTest, pyTrain, pyTest = DataPrep(pData, verbose=True, window_size = pWindowSize, grader_params=pGraderParams) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-djvNNwekrC",
        "outputId": "c938dd99-b487-47a1-a7ec-c4099538a488"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data prep start\n",
            "...Indexing complete. Index differential: 60000\n",
            "...Columns removed\n",
            "...Renaming complete\n",
            "...Starting indicators\n",
            "      Indicator sma-20 identified\n",
            "      Indicator found in stored list\n",
            "      Indicator sd-20 identified\n",
            "      Indicator found in stored list\n",
            "      Indicator sma-10 identified\n",
            "      Indicator found in stored list\n",
            "      Indicator sd-10 identified\n",
            "      Indicator found in stored list\n",
            "...Indicators complete\n",
            "...Grader function called\n",
            "      Long trade labels complete\n",
            "      Short trade labels complete\n",
            "...Grader function complete\n",
            "...Data trimmed\n",
            "...Data normalized\n",
            "...Train-test split created\n",
            "...Starting tensor creation\n",
            "      Train tensor with 8063 batches, 30 window size\n",
            "      Train tensor created with shape : (8063, 30, 10)\n",
            "      Test tensor with 1994 batches, 30 window size\n",
            "      Test tensor created with shape : (1994, 30, 10)\n",
            "...Tensor creation complete\n",
            "Data Prep Complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pretty lost on this part, just want to get it working. This is taken almost directly from the tf.keras documentation\n",
        "model = tf.keras.Sequential()\n",
        "model.add(LSTM(128, input_shape=pxTrain.shape[1:3], activation='relu', return_sequences=True))\n",
        "model.add(LSTM(64, activation='relu', return_sequences=True))\n",
        "model.add(LSTM(32, activation='relu'))\n",
        "model.add(Dense(2, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy', 'accuracy'])\n",
        "model.fit(pxTrain, pyTrain, epochs=1, use_multiprocessing=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irArFKHqQYVk",
        "outputId": "4b9c0068-2312-488e-b50a-6a5830749c07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "252/252 [==============================] - 18s 56ms/step - loss: 0.6750 - binary_accuracy: 0.5982 - accuracy: 0.4627\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff57b5fb750>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(pxTest, pyTest, use_multiprocessing=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rhcZK3kXag7",
        "outputId": "2c9f0a27-a194-4efc-ac02-d024f9b7c3d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 1s 14ms/step - loss: 0.6631 - binary_accuracy: 0.6241 - accuracy: 0.6269\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6631406545639038, 0.6241223812103271, 0.6268806457519531]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.4 Prototype Compiled Properly\n",
        "\n",
        "The prototype made it all the way through to the training section of the model. To this point, all I've really done is familiarize myself with the architecture of the LSTM model. Most of what I've done above is likely incorrect or improper. However, now that I understand how it all plays together, I can start really diving into what needs doing.\n",
        "\n",
        "Binary accuracy probably isn't the best metric. I was shooting for a small profit of 0.1%, and a risk/reward of 2. If I follow through with this math, it means that in 62% of trades, a profit of 0.001 was achieved, and in the remaining 38% of the trades, the profit was -0.0005, due to the factor of 2 in the rr. The net profit per trade, which is likely the metric of accuracy that I should consider the most, is then the weighted sum of the two:\n",
        "$$62\\%\\cdot(0.001) - 38\\%\\cdot(0.0005) = 0.043\\%$$\n",
        "This looks promising, but the accuracy also includes entries where a trade was indeterminate, i.e. when I would not be entering a trade. More analysis on the data is required before drawing any conclusions."
      ],
      "metadata": {
        "id": "In5B0JBNBPZC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.5 Some Model Analysis\n"
      ],
      "metadata": {
        "id": "ddg5x1vKL2CF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Result histogram\n",
        "I'd like to see some of what the model does with the prototype parameters, so I can better understand what's going on. I'll start with a binned histogram of the predictions over the true values to see the distribution. Of course, this could be useful later so I'll make a function for it."
      ],
      "metadata": {
        "id": "CoapYC7TtAoe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#The results are in pairs for each data point with \n",
        "def results_histogram(df):\n",
        "\n",
        "    buy_results, sell_results = np.transpose(model.predict(pxTest))\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(15,5))\n",
        "    axes[0].hist(buy_results, bins=10)\n",
        "    axes[0].set_title(\"Long trade predictions\")\n",
        "    axes[1].hist(sell_results, bins=10)\n",
        "    axes[1].set_title(\"Short trade predictions\")\n",
        "\n",
        "    for i in [0,1]:\n",
        "        axes[0].set_xlabel(\"Predictions\")\n",
        "        axes[0].set_ylabel(\"Bin count\")\n",
        "\n",
        "results_histogram(pxTest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "rtLit5-atRJi",
        "outputId": "34ec7e09-8d23-40a5-ffd3-aa2bd533143e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clearly, something is amiss. The model is only giving results between a very limited range, which is a large failure. I think before I can continute, I need to find the source of this error. My first instinct is that perhaps I'm not treating the LSTM properly. I've been treating it like a classifier, but I think I should be treating it like a regression algorithm. Currently, my grader function classifies a data point as either being a good long trade, or a good short trade. The idea was then the model would be able to provide a binary 0 or 1 result. As I understand it, the LSTM would be better at predicting a continuous value, such as the closing price increase from one point to the next.\n",
        "\n",
        "I realize now, that I likely need to frame this as a regression problem instead. First, though, I'm going to try continuing as a classifier and simply change how I encode the results.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "lIZlvQ1YxWql"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.6 Changing the encoding scheme"
      ],
      "metadata": {
        "id": "jfALyEVcM6eO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.6.1 \"Why does it need changing?\"\n",
        "\n",
        "\n",
        "\n",
        "When the algorithm sees two y-columns, the LSTM is designed to read that as being two timesteps into the future. Instead of seeing a buy columns and a sell column, it sees the first prediction timestep, and then the second. I need to encode the buying or selling into a single operator with range -1 to 1, encoded as follows:\n",
        "*  -1 : It's a good trade to go short\n",
        "*   0 : Either the trade window expired, or the result was indeterminate\n",
        "*   1 : It's a good trade to go long.\n",
        "\n",
        "I'll redefine the data prep and grader functions to account for this:\n",
        "I realized when thinking about how to implement the above encoding that it was rather boring information. If I could somehow encorporate both how long it took to find the trade, as well as the resulting trade polarity. I know that the negatives will indicate a short trade, and positive will encode a long trade. I think the simplest approach seems to be to score the data uniformly, aka -1 for a short, or +1 for a long. However, this fails to capture the length of time it took to find the trade. Since I am specifying the trade parameters, I think I should incentivise trades that are executed quickly. Because of this, I'll try first using some kind of scale that incentivises quick trades over long ones, such as an inverse exponential.\n",
        "\n",
        "I also need to be able to handle working through the data in series, and I need a way of catching exceptions where both trades execute in time. Because I am now weighing the results based on how fast they are, both results will be non-zero. I can then take the absolute value of both, and the smallest one means it executed first. This will always be true for any distribution where the incentive is strictly decreasing as you interate along looking for the trade. \n",
        "\n",
        "In the code below, I am using the index k+1 to assign the result in the long trade section. This will be written immediately into the output list. Next when the short trade is running"
      ],
      "metadata": {
        "id": "ufegviy8NCCM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.6.2 Re-designing the grader() and dataPrep() functions\n",
        "\n",
        "The long trade is checked first. When it finds a trade, instead of assigning a 1, it will assign the value of k+1. This ensures that there are no zeros, and the result scales into the positive with the length it took to find the trade.\n",
        "\n",
        "I also think it's worth trying to format the data in a way that makes the most sense to the computer, a linear scale from -n_tries to n_tries is quite unwieldy, and so I should find a way to normalize the data."
      ],
      "metadata": {
        "id": "X0hUNV5YFtoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def grader_scaled(df, *args):\n",
        "    \"\"\"\n",
        "    Grader function, takes a pd DataFrame 'df' as input and outputs whether or not a buy (long trade) or\n",
        "        a sell (short trade) at the current data point would trigger a stop loss or a take profit within\n",
        "        'n_tries' data points at a reward/risk ratio and profit level of 'rr' and 'profit', respectively.\n",
        "\n",
        "\n",
        "        df        :  pandas DataFrame with shape (1,x)\n",
        "\n",
        "        *args variables\n",
        "        profit    :  Number, The desired profit, in percentage form\n",
        "        rr        :  Number, The reward/risk ratio, used to calculate stop-loss and take-profit\n",
        "        n_tries   :  Number, Number of data points to look into the future for the SL or TP\n",
        "        exp_scale :  Number, the scaling factor for the exponential function used to encode information\n",
        "\n",
        "\n",
        "    Re-design discussion: Now that the data is scaled relatively, in order to execute properly the grader\n",
        "        function will now compare the TP and SL levels to the product of all entries up to the current index.\n",
        "        Conveniently, the TP and SL levels are now single constants, and no longer large lists constructed from df.\n",
        "    \"\"\"\n",
        "    # Unpack the args\n",
        "    args = list(args)\n",
        "    profit, rr, n_tries, exp_scale = args[0]\n",
        "\n",
        "    # Create the inverse exponential function that will act as the scaling factor for the data.\n",
        "    exp_list = np.arange(1, n_tries)\n",
        "    exp_list = np.exp( -np.abs(exp_list) * exp_scale / n_tries )\n",
        "\n",
        "    df = np.array(df)\n",
        "\n",
        "    # First, I am calculating as if the trade is long. So, I am looking for a TP above the close, with a corresponding\n",
        "    #     SL below the close. These are specified by the function parameters.\n",
        "\n",
        "    # TP is now simply one plus the profit, which makes it in our desired form (12.3% - > 1.23)\n",
        "    # SL is calculated similarly with one minus the quantity profit divided by the rr ratio\n",
        "    tp_long = 1 + profit\n",
        "    sl_long = 1 - (profit / rr)\n",
        "\n",
        "    # If the trade type is short, I are looking for a TP below the close, with a corresponding SL above the close\n",
        "        #     specified similarly by the profit and reward/risk ratio.\n",
        "    tp_short = 1 - profit\n",
        "    sl_short = 1 + (profit / rr)\n",
        "\n",
        "    # There needs to be a running temp variable which will hold the current value of the closing tick relative to our\n",
        "    #    starting tick. This will be initialized to 1 every time the outer loop runs.\n",
        "    increase = 1\n",
        "\n",
        "    result_list = np.zeros(df.shape)\n",
        "\n",
        "    for i, val in enumerate(df):\n",
        "        # Initialize values.\n",
        "        # The percent increase in decimal form since k=0\n",
        "        increase = 1\n",
        "        # The index where the long trade executed\n",
        "        i_long  = 0\n",
        "        # The index where the short trade executed\n",
        "        i_short = 0\n",
        "\n",
        "        # Iterate over the next n_tries values\n",
        "        # When i=0, it's being compared to itself, so instead I'll start at i+1\n",
        "        for k in range(i+1, i+n_tries):\n",
        "\n",
        "            try:\n",
        "                # Find the relative change since k=0\n",
        "                increase = increase*df[k]\n",
        "            except IndexError:\n",
        "                # This IndexError exception only triggers when (k=i+n_tries) exceeds the elements in df\n",
        "                break\n",
        "\n",
        "            # Compare to situations and assign result values accordingly. When a take-profit is triggered,\n",
        "            #     the value of i_short/i_long will be positive. When stop-loss is triggered, it will be negative.\n",
        "            if i_long == 0:\n",
        "                if increase >= tp_long:\n",
        "                    i_long = k-i-1\n",
        "                elif increase <= sl_long:\n",
        "                    i_long = -(k-i-1)\n",
        "                \n",
        "            if i_short == 0:\n",
        "                if increase <= tp_short:\n",
        "                    i_short = k-i-1\n",
        "                elif increase >= sl_short:\n",
        "                    i_short = -(k-i-1)\n",
        "        \n",
        "        # Note that i_long and i_short are guaranteed to have opposite sign if one is positive.\n",
        "        # I did not implement the scaling of the result here, but if I wanted to, I would uncomment\n",
        "        #     the below lines.\n",
        "        if i_long > 0:\n",
        "            result_list[i] = 1\n",
        "        #   result_list[i] = exp_list[i_long]\n",
        "        elif i_short > 0:\n",
        "            result_list[i] = -1\n",
        "        #   result_list[i] = -exp_list[i_short]\n",
        "\n",
        "    return result_list"
      ],
      "metadata": {
        "id": "FtvP-1HaF9AS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def DataPrep(df, \n",
        "             test_ratio = 0.2,\n",
        "             window_size = 10,\n",
        "             return_frame = False,\n",
        "             verbose = False,\n",
        "             grader_params = [0.001, 2, 30],\n",
        "             remove = [\"date\", \"symbol\", \"Volume BTC\", \"tradecount\", \"unix\"], \n",
        "             indicators = [(\"sma\", 20), (\"sd\", 20), (\"sma\", 10), (\"sd\", 10)]\n",
        "             ):\n",
        "    \"\"\"\n",
        "        Parameters\n",
        "    df            : Pandas DataFrame, The data set to prepare. Has known structure and layout.\n",
        "    test_ratio    : Number between 0 and 1, The ratio of test data to training data\n",
        "    window_size   : Number, the amount of data points per batch\n",
        "    return_frame  : Whether or not I return the non-LSTM-modified DataFrame (useful for debugging)\n",
        "    verbose       : Whether or not to print progress from the function call.\n",
        "    grader_params : List, The parameters to be sent to the grader function (profit, rr, n)\n",
        "    remove        : List, The columns to be removed\n",
        "    indicators    : List, The indicators to be added\n",
        "        Returns\n",
        "    batch_df      : Pandas DataFrame, The rank-3 tensor to be used in the LSTM layer (batches, window, features)\n",
        "    df            : Pandas DataFrame, Optional, The non-windowed DataFrame (index, features)\n",
        "    \"\"\"\n",
        "\n",
        "    if verbose: print(\"Data prep start\")\n",
        "    # Define some variables to help trim later\n",
        "    max_period = 0\n",
        "    grader_period = grader_params[2]\n",
        "\n",
        "    # Indexing and bulk removal -- Want oldest data first so RNN reads along positive time direction\n",
        "    df = df.loc[::-1].reset_index(drop=True)\n",
        "    # Index differential is used to ensure that the list did in fact get reversed\n",
        "    if verbose: print(\"...Indexing complete. Index differential: %i\" %(df[\"unix\"].iloc[1] - df[\"unix\"].iloc[0]))\n",
        "    df = df.drop(columns = remove)\n",
        "    if verbose: print(\"...Columns removed\")\n",
        "\n",
        "    # Any base renaming to be done\n",
        "    df[\"vol\"] = copy.copy(df[\"Volume USDT\"])\n",
        "    df = df.drop(\"Volume USDT\", axis=1)\n",
        "    if verbose: print(\"...Renaming complete\")\n",
        "\n",
        "    # Indicator calculator. For each tuple in \"indicators\", relevant information\n",
        "    #    is passed to add the desired indicator to the data set. If the indicator\n",
        "    #    has already been calculated and stored in the stored_indicators list,\n",
        "    #    it will pull from that instead of calulating it from scratch.\n",
        "    if verbose: print(\"...Starting indicators\")\n",
        "    for item in indicators:\n",
        "\n",
        "        #Identify the indicator and period\n",
        "        indicator, period = item\n",
        "        #Create the label \"indicator-period\"\n",
        "        label = indicator + \"-\" + str(period)\n",
        "        if verbose: print(\"      Indicator %s identified\" %label)\n",
        "\n",
        "        # I need to know the max period of the indicators to know how much data\n",
        "        #    to trim from the beginning of the data set. This is to avoid NaN in\n",
        "        #    our data.\n",
        "        if period > max_period:\n",
        "            max_period = period\n",
        "\n",
        "        # If I have already calculated this label and it is stored in our list:\n",
        "        if label in stored_indicators.columns:\n",
        "            if verbose: print(\"      Indicator found in stored list\")\n",
        "            df[label] = copy.copy(stored_indicators[label])\n",
        "        # If I have not yet calculated this label\n",
        "        else:\n",
        "            # Use the dictionary to calculate the desired indicator and store it in df\n",
        "            df[label] = indicator_dict[indicator](df[\"close\"], period)\n",
        "            # Also store the indicator in the stored list for further use\n",
        "            stored_indicators[label] = copy.copy(df[label])\n",
        "            if verbose: print(\"      New indicator %s added to list\" %label)\n",
        "\n",
        "    if verbose: print(\"...Indicators complete\")\n",
        "\n",
        "\n",
        "\n",
        "    if verbose: print(\"...Starting data scaling\")\n",
        "    # Iterate over each column\n",
        "    for col in df.columns:\n",
        "\n",
        "        # Iterate over each value, backwards\n",
        "        for i in range(df.shape[0]-1, 0, -1):\n",
        "            df.at[i, col] = df.at[i, col] / df.at[i-1, col]\n",
        "        \n",
        "        df.at[0,col] = 1\n",
        "\n",
        "        if verbose: print(\"      Column ( %s ) Completed\" %col)\n",
        "    if verbose: print(\"...Finished data scaling\")\n",
        "\n",
        "    \"\"\"\n",
        "    Obsolete, now I need to scale the data based on the relative size to the previous entry. See above code.\n",
        "\n",
        "    # Normalize all the data\n",
        "    for col in df.columns:\n",
        "        df[col] = normalize(df[col]) \n",
        "    if verbose: print(\"...Data normalized\")\n",
        "    \"\"\"\n",
        "\n",
        "    if verbose: print(\"...Grader function called\")\n",
        "    # Calculate the labels for the data set using the grader_params provided\n",
        "    df[\"result\"] = grader_scaled(df[\"close\"], grader_params)\n",
        "    if verbose: print(\"...Grader function complete\")\n",
        "\n",
        "    # Trim the data set based on the largest indicator period and the grader period\n",
        "    df = df.iloc[max_period : -1*grader_period]\n",
        "    if verbose: print(\"...Data trimmed\")\n",
        "\n",
        "    # Create the train and test splits for the data\n",
        "    train, test = train_test_split(df, test_size = test_ratio, shuffle=False)\n",
        "    train_labels = copy.copy(train[\"result\"])\n",
        "    train = train.drop(\"result\", axis=1)\n",
        "    test_labels = copy.copy(test[\"result\"])\n",
        "    test = test.drop(\"result\", axis=1)\n",
        "    if verbose: print(\"...Train-test split created\")\n",
        "\n",
        "    # Define some variables to be used during the tensor creation\n",
        "    train_batches = train.shape[0] - window_size\n",
        "    test_batches = test.shape[0] - window_size\n",
        "    num_features = train.shape[1]\n",
        "\n",
        "    # Create the tensor for use in the LSTM layer\n",
        "    if verbose: print(\"...Starting tensor creation\")\n",
        "    batch_train = np.empty(shape = (train_batches, window_size, num_features), dtype = np.float32)\n",
        "    batch_test = np.empty(shape = (test_batches, window_size, num_features), dtype = np.float32)\n",
        "\n",
        "    if verbose: print(\"      Train tensor with %i batches, %i window size\" %(train_batches, window_size))\n",
        "    for i in range(train_batches):\n",
        "        batch_train[i] = train.iloc[ i : (i + window_size) ]\n",
        "    #    for v in range(window_size):\n",
        "    #        batch_train[i][v] = train.iloc[i + v]\n",
        "    if verbose: print(\"      Train tensor created with shape :\", batch_train.shape)\n",
        "\n",
        "    if verbose: print(\"      Test tensor with %i batches, %i window size\" %(test_batches, window_size))\n",
        "    for i in range(test_batches):\n",
        "        batch_test [i] = test.iloc[ i : (i + window_size)]\n",
        "    #    for v in range(window_size):\n",
        "    #        batch_test[i][v] = test.iloc[i + v]\n",
        "    if verbose: print(\"      Test tensor created with shape :\", batch_test.shape)\n",
        "    if verbose: print(\"...Tensor creation complete\")\n",
        "    if verbose: print(\"Data prep complete\")\n",
        "\n",
        "\n",
        "    if return_frame: return batch_train, batch_test, train_labels[window_size:], test_labels[window_size:], df\n",
        "\n",
        "    return batch_train, batch_test, train_labels[window_size:], test_labels[window_size:]"
      ],
      "metadata": {
        "id": "tSgbh8pvR0D2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.7 Testing the new functions\n",
        "\n",
        "As a bonus, the DataPrep function is now significantly faster!"
      ],
      "metadata": {
        "id": "P7naNw2RhIQ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pGraderParams = [0.01, 2, 30, 2]\n",
        "pWindowSize = 30\n",
        "pxTrain, pxTest, pyTrain, pyTest, df = DataPrep(pData, verbose=True, window_size = pWindowSize, grader_params=pGraderParams, return_frame=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOtP96cYhBrf",
        "outputId": "5c117c08-83a7-4789-d485-38c2593187db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data prep start\n",
            "...Indexing complete. Index differential: 60000\n",
            "...Columns removed\n",
            "...Renaming complete\n",
            "...Starting indicators\n",
            "      Indicator sma-20 identified\n",
            "      Indicator found in stored list\n",
            "      Indicator sd-20 identified\n",
            "      Indicator found in stored list\n",
            "      Indicator sma-10 identified\n",
            "      Indicator found in stored list\n",
            "      Indicator sd-10 identified\n",
            "      Indicator found in stored list\n",
            "...Indicators complete\n",
            "...Starting data scaling\n",
            "      Column ( open ) Completed\n",
            "      Column ( high ) Completed\n",
            "      Column ( low ) Completed\n",
            "      Column ( close ) Completed\n",
            "      Column ( vol ) Completed\n",
            "      Column ( sma-20 ) Completed\n",
            "      Column ( sd-20 ) Completed\n",
            "      Column ( sma-10 ) Completed\n",
            "      Column ( sd-10 ) Completed\n",
            "...Finished data scaling\n",
            "...Grader function called\n",
            "...Grader function complete\n",
            "...Data trimmed\n",
            "...Train-test split created\n",
            "...Starting tensor creation\n",
            "      Train tensor with 8079 batches, 30 window size\n",
            "      Train tensor created with shape : (8079, 30, 9)\n",
            "      Test tensor with 1998 batches, 30 window size\n",
            "      Test tensor created with shape : (1998, 30, 9)\n",
            "...Tensor creation complete\n",
            "Data prep complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(df[\"result\"], return_counts=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaiaDjtEvKhH",
        "outputId": "545d0a95-67d5-46d9-f434-3cc87a2931b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-1.,  0.,  1.]), array([ 265, 9499,  373]))"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(LSTM(128, input_shape=pxTrain.shape[1:3], activation='relu', return_sequences=True))\n",
        "model.add(LSTM(64, activation='relu', return_sequences=True))\n",
        "model.add(LSTM(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy', 'accuracy'])\n",
        "model.fit(pxTrain, pyTrain, epochs=1, use_multiprocessing=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anzPETn8FbE4",
        "outputId": "73960f95-9eb0-46c5-bb6a-09014355de39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "253/253 [==============================] - 16s 51ms/step - loss: 0.1031 - binary_accuracy: 0.9328 - accuracy: 0.9328\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff56f61c410>"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, an accuracy of 0.932 looks quite spectacular at first, until I look a little closer. In the results column of my frame, there is about 9500 indeterminate trades (value of 0) and a remaining ~500 which are either -1 or 1. If the algorithm simply guessed 0 for every single data point, it would achieve an accuracy of 95%. I'll look at the histogram of the guesses:"
      ],
      "metadata": {
        "id": "Cxgs7DRKm-M_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_preds = model.predict(pxTest)\n",
        "\n",
        "plt.hist(y_preds, bins=10);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "xLM0-Kr5qrTX",
        "outputId": "24d65004-dbfc-48dc-99ff-5c3f8084825b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As I presumed, the model is guessing nearly zero, however there is a defined distribution here. I wonder what would happen if I massaged this data a little bit to pull out the underlying results. The prediction of zero should be the average, and then -1 and 1 should scale outward from there depending on a threshold value. A simple application would be to take the mean as the zero point, and a threshold of one standard deviation."
      ],
      "metadata": {
        "id": "b2qm4HFXr5PL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def results_format(results, scaling = 1):\n",
        "\n",
        "    results = np.array(normalize(copy.copy(results)))\n",
        "    mean = np.mean(results)\n",
        "    std = np.std(results)\n",
        "\n",
        "    for i, val in enumerate(results):\n",
        "        if val > mean+(scaling*std):\n",
        "            results[i] = 1\n",
        "        elif val < mean- (scaling*std):\n",
        "            results[i] = -1\n",
        "        else:\n",
        "            results[i] = 0\n",
        "\n",
        "    return results\n",
        "\n",
        "y_pred_scaled = results_format(y_preds)\n",
        "\n",
        "acc = tf.keras.metrics.Accuracy()\n",
        "acc.update_state(y_pred_scaled, pyTest)\n",
        "acc.result().numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ol6EaD7gsEsf",
        "outputId": "ab3a1b6b-f68f-4681-e068-22c844b1597d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5605606"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(y_pred_scaled);\n",
        "print(\"Counts of results in predictions: \", np.unique(y_pred_scaled, return_counts=True))\n",
        "print(\"Counts of results in true values: \", np.unique(pyTest, return_counts=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "Zw0HSURUuHDg",
        "outputId": "b6380203-e8d2-4b4f-e5c5-7c9aa56a4219"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counts of results in predictions:  (array([-1.,  0.,  1.], dtype=float32), array([ 460, 1175,  363]))\n",
            "Counts of results in true values:  (array([-1.,  0.,  1.]), array([  54, 1879,   65]))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "At the end of the day, a model like this is supposed to make money. I'll calculate the net profit if using the model, as that will be the most reliable metric to use. It's useful to see above that all predicted and true values are now in +1, 0, -1, which will make it easier to calculate the net profit."
      ],
      "metadata": {
        "id": "zm01a0Scud2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def net_profit(y_pred, y_true, profit):\n",
        "\n",
        "    # Start at a net profit of 0, no gain or loss. Make sure to use the same\n",
        "    #     profit as was used in the data prep. Profit is also sent as a multiplicative value,\n",
        "    #     i.e. 0.01 => a 1% profit. If I am spending $100 every trade, then the net profit is the\n",
        "    #     sum of successful and unsuccessul trades, each individually yielding a profit of +/- 'profit'.\n",
        "\n",
        "    net_profit = 0\n",
        "    \n",
        "    for i,val in enumerate(y_pred):\n",
        "\n",
        "        # However, I would not be entering into an indeterminate trade, and so I must only consider non-zero\n",
        "        #     entries\n",
        "        if val != 0:\n",
        "\n",
        "            # Knowing that our values are exactly -1 or 1 at this point, it's a simple matter of equating for\n",
        "            #      the result.\n",
        "            if val == y_true.iloc[i]:\n",
        "                net_profit += profit\n",
        "            else:\n",
        "                net_profit -= profit\n",
        "    \n",
        "    return net_profit\n",
        "\n",
        "print(net_profit(y_pred_scaled, pyTest, pGraderParams[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meMiZP0jukrD",
        "outputId": "3f8e7125-2adb-4977-c7fd-3cde05b0e28f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-8.069999999999872\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that this metric is defined, I'll vary the scaling factor in result_format to get the highest profit possible. I'll be using a scipy minimization function. In order to use that, we need the profit to be in the negative. I'll splice the two above functions to make something that will be passable to the scipy minimize function."
      ],
      "metadata": {
        "id": "c2V27pdYwT7k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def minimizer_function(scaling_factor = 1 , *args):\n",
        "    y_pred, y_true, profit = args[0]\n",
        "\n",
        "    # Scaling section\n",
        "    y_pred = np.array(normalize(copy.copy(y_pred)))\n",
        "    mean = np.mean(y_pred)\n",
        "    std = np.std(y_pred)\n",
        "\n",
        "    for i, val in enumerate(y_pred):\n",
        "        if val > mean+(scaling_factor*std):\n",
        "            y_pred[i] = 1\n",
        "        elif val < mean- (scaling_factor*std):\n",
        "            y_pred[i] = -1\n",
        "        else:\n",
        "            y_pred[i] = 0\n",
        "\n",
        "    # Profit Section\n",
        "    net_profit = 0\n",
        "    \n",
        "    for i,val in enumerate(y_pred):\n",
        "        if val != 0:\n",
        "            if val == y_true.iloc[i]:\n",
        "                net_profit += profit\n",
        "            else:\n",
        "                net_profit -= profit\n",
        "    \n",
        "    return -net_profit\n",
        "\n",
        "minimizer_function(1, (y_preds, pyTest, pGraderParams[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-rh5kUEyaNX",
        "outputId": "a4e3109d-cda4-4f6a-fa5e-294978168e97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.069999999999872"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Same result as above, now with a negative sign in front since we want profit to be negative for minimization. Let's pass this to the scipy optimizer!"
      ],
      "metadata": {
        "id": "FUyiPIixy9Hn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.optimize import minimize_scalar\n",
        "\n",
        "minimize_scalar(minimizer_function, args=[y_preds, pyTest, pGraderParams[0]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwT61y0dzCm_",
        "outputId": "c364a910-9cba-4de1-b918-ca004cbab1ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     fun: 0\n",
              "    nfev: 37\n",
              "     nit: 32\n",
              " success: True\n",
              "       x: 2.514978237480026"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "minimizer_function(2.515, (y_preds, pyTest, pGraderParams[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-u7PbhJV0ceR",
        "outputId": "26b58dbf-5111-4058-8a5c-0add4d5c8452"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems like the limit has been reached, even with scaling the function optimially it still plateaus at zero net profit. At this point, I've ran out of time for the project, and if it gets updated in the future it will be after the time I wanted to have it finished."
      ],
      "metadata": {
        "id": "VAUA_e2B1RVu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary\n",
        "\n",
        "In the end, here are the key points:\n",
        "\n",
        "### DataPrep Function\n",
        "The final DataPrep function, which takes DataFrame input with known formatting. This function will:\n",
        "* Remove desired columns\n",
        "* Add desired technical indicators\n",
        "* Grade the data using the grader function, which assigns a value in [-1, 0, 1] depending on the result of the trade\n",
        "* Split the data into training and testing sets, which are already batched for use in the LSTM as 3-D tensors\n",
        "\n",
        "All of the above points are able to be modified through the arguments sent to the DataPrep function.\n",
        "\n",
        "The DataPrep function went through two iterations, the first of which simply normalized all the data across the entire set. This seemed counterintuitive to me once I thought more about it, as the more important piece of data is the relative change between data points, not the absolute value.\n",
        "\n",
        "The second iteration of the DataPrep function addressed this by scaling the data relative to the previous value. That is, if point A had a value of 100 and point B had a value of 110, point B would be replace with a 1.1, meaning it was 1.1x(point A). The first element was chosen to have a value of 1.\n",
        "\n",
        "### Grader Function\n",
        "The final Grader function, which takes the DataFrame column of closing prices. This function also takes the desired profit, reward/risk ratio, and number of timesteps, in order to calculate whether or not a trade at each point would result in a success. This result is encoded as an element of [-1, 0, 1], depending on whether or not a short trade would succeed, the trade was indeterminate, or a long trade would succeed, respectively.\n",
        "\n",
        "Because the Grader and DataPrep functions were so closely related, the Grader function also had two iterations. In the first iteration, the Grader function considered the absolute price levels in order to determine if the trade was successful. This got more complicated when the DataPrep function scaled the data to be relative. The final Grader function used different math to compare whether or not the trade was successful, based on the sequential relative increases in price from one data point to the next.\n",
        "\n",
        "### LSTM Network \n",
        "\n",
        "Likely the weakest part of the project, my implementation of the LSTM network was likely lacking in several key areas. While I don't know them now, I will continue to work on this project and hopefully reach a point where I understand where all my shortcomings were located. My initial list of guesses looks something like this:\n",
        "\n",
        "* Perhaps the data being normalized holds more weight than I gave credit\n",
        "* Custom metrics for accuracy which exclude the indeterminate trades would provide stronger insight\n",
        "* Using more combinations of TAs to see if performance of the model increases\n",
        "\n",
        "**The single most important factor, in my opinion, is the loss function**\n",
        "\n",
        "I think a custom loss function is the single best improvement I can make for this type of problem. I think there is nothing inherently wrong with the classifier approach I have taken, but no loss function properly takes it into account. There is no loss, or gain, when a prediction of zero is made, and the result is zero. It is much more important to know the result of the trade when a prediction was really made. If I return to this project, the first change I would make is to implement a custom loss function which ignores all predictions of zero.\n"
      ],
      "metadata": {
        "id": "eJsyn1y67nJN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ADPPENDIX\n",
        "\n",
        "Also known as my other failed attempts. It is not necessarily as well documented, especially near the end. The summary of the approaches are:\n",
        "\n",
        "First, using a basic classifier algorithm with several technical indicators\n",
        "Second, using a standard deep learning network with several technical indicators\n",
        "\n",
        "At this point, I realized I should likely be using recurring neural networks, and that is where the above section started, chronologically."
      ],
      "metadata": {
        "id": "Uv_FZxg4Celj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Naive approach"
      ],
      "metadata": {
        "id": "VHkD6p_FyLCx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Key points:\n",
        "There are a few important notes about how the algorithm will be designed and implemented, and I've summarised them below:\n",
        "\n",
        "*   TA Indicators\n",
        "    *   Several TA indicators will be implemented in the first section of this notebook\n",
        "    *   Different combinations of TA indicators will be tested when training the algorithm in order to find the highest performing combination.\n",
        "*   Moving Averages (MAs)\n",
        "    *   The MA is a fundamental tool in technical analysis, and so I will be using a spread of MAs to assist in our training.\n",
        "    *   The MA periods will be determined by something along the lines of: \n",
        "$(MA)_i = 2 \\lceil(x^i)\\rceil$\n",
        "    *   That is, the $i$'th MA to be used will be the $i$'th power of $x$, where I let $x$ vary between 1 and 2.\n",
        "*   Redundancy\n",
        "    *    To make the data easier to parse, any TA indicators that return an absolute price level in any way (e.g. moving averages, bollinger bands, etc.) will instead be returned in terms of relative price level (i.e. percent difference from current price level).\n",
        "*   Trades\n",
        "    *    Trades will be executed using a standardized $100. The goal is to find the percent profit, and so it makes things easier to standardize the trade amount.\n",
        "    *    Each iteration of the training algorithm will use a different risk/reward (r/r) ratio.\n",
        "    *    The output of the algorithm will, in some way, indicate either a buy, or a sale, at each particular data point. This information will be combined with the \n",
        "    *    Whether or not the trade is executed will depend on if the expected yield from the trade is above the so-called \"trade threshold\", i.e. 5% (most likely much, much smaller in practice)\n",
        "\n",
        "\n",
        "## Success Measurement\n",
        "\n",
        "Success will be measured using a binary pass/fail system. The algorithm will \n",
        "\n",
        "## Starting with the data"
      ],
      "metadata": {
        "id": "5HCG9QKNxtwC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Nc7xlw3IZWb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "36b80921-1882-44b6-99ff-cc3abe749e3b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ff2ac642-01f3-48f8-8337-b2d3b503a17b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>https://www.CryptoDataDownload.com</th>\n",
              "      <th>Unnamed: 1</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "      <th>Unnamed: 4</th>\n",
              "      <th>Unnamed: 5</th>\n",
              "      <th>Unnamed: 6</th>\n",
              "      <th>Unnamed: 7</th>\n",
              "      <th>Unnamed: 8</th>\n",
              "      <th>Unnamed: 9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>unix</td>\n",
              "      <td>date</td>\n",
              "      <td>symbol</td>\n",
              "      <td>open</td>\n",
              "      <td>high</td>\n",
              "      <td>low</td>\n",
              "      <td>close</td>\n",
              "      <td>Volume BTC</td>\n",
              "      <td>Volume USDT</td>\n",
              "      <td>tradecount</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.64E+12</td>\n",
              "      <td>2021-12-12 0:00</td>\n",
              "      <td>BTC/USDT</td>\n",
              "      <td>49389.99</td>\n",
              "      <td>49577</td>\n",
              "      <td>49301.07</td>\n",
              "      <td>49482.13</td>\n",
              "      <td>591.84649</td>\n",
              "      <td>29259916.06</td>\n",
              "      <td>17040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.64E+12</td>\n",
              "      <td>2021-12-11 23:00</td>\n",
              "      <td>BTC/USDT</td>\n",
              "      <td>48826.36</td>\n",
              "      <td>49485.71</td>\n",
              "      <td>48793.65</td>\n",
              "      <td>49389.99</td>\n",
              "      <td>1303.91272</td>\n",
              "      <td>64211479.93</td>\n",
              "      <td>45868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.64E+12</td>\n",
              "      <td>2021-12-11 22:00</td>\n",
              "      <td>BTC/USDT</td>\n",
              "      <td>48779.31</td>\n",
              "      <td>49146.21</td>\n",
              "      <td>48628.36</td>\n",
              "      <td>48826.36</td>\n",
              "      <td>821.94948</td>\n",
              "      <td>40150780.57</td>\n",
              "      <td>32006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.64E+12</td>\n",
              "      <td>2021-12-11 21:00</td>\n",
              "      <td>BTC/USDT</td>\n",
              "      <td>48564.06</td>\n",
              "      <td>48839.95</td>\n",
              "      <td>48390.22</td>\n",
              "      <td>48782.79</td>\n",
              "      <td>693.14915</td>\n",
              "      <td>33652418.81</td>\n",
              "      <td>28574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40492</th>\n",
              "      <td>1502956800</td>\n",
              "      <td>2017-08-17 08-AM</td>\n",
              "      <td>BTC/USDT</td>\n",
              "      <td>4349.99</td>\n",
              "      <td>4377.85</td>\n",
              "      <td>4333.32</td>\n",
              "      <td>4360.69</td>\n",
              "      <td>0.9499</td>\n",
              "      <td>4139.7</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40493</th>\n",
              "      <td>1502953200</td>\n",
              "      <td>2017-08-17 07-AM</td>\n",
              "      <td>BTC/USDT</td>\n",
              "      <td>4324.35</td>\n",
              "      <td>4349.99</td>\n",
              "      <td>4287.41</td>\n",
              "      <td>4349.99</td>\n",
              "      <td>4.44</td>\n",
              "      <td>19241.06</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40494</th>\n",
              "      <td>1502949600</td>\n",
              "      <td>2017-08-17 06-AM</td>\n",
              "      <td>BTC/USDT</td>\n",
              "      <td>4315.32</td>\n",
              "      <td>4345.45</td>\n",
              "      <td>4309.37</td>\n",
              "      <td>4324.35</td>\n",
              "      <td>7.23</td>\n",
              "      <td>31282.31</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40495</th>\n",
              "      <td>1502946000</td>\n",
              "      <td>2017-08-17 05-AM</td>\n",
              "      <td>BTC/USDT</td>\n",
              "      <td>4308.83</td>\n",
              "      <td>4328.69</td>\n",
              "      <td>4291.37</td>\n",
              "      <td>4315.32</td>\n",
              "      <td>23.23</td>\n",
              "      <td>100304.82</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40496</th>\n",
              "      <td>1502942400</td>\n",
              "      <td>2017-08-17 04-AM</td>\n",
              "      <td>BTC/USDT</td>\n",
              "      <td>16199.91</td>\n",
              "      <td>16199.91</td>\n",
              "      <td>4261.32</td>\n",
              "      <td>4308.83</td>\n",
              "      <td>44.51</td>\n",
              "      <td>190952.85</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>40497 rows  10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff2ac642-01f3-48f8-8337-b2d3b503a17b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ff2ac642-01f3-48f8-8337-b2d3b503a17b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ff2ac642-01f3-48f8-8337-b2d3b503a17b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      https://www.CryptoDataDownload.com  ...  Unnamed: 9\n",
              "0                                   unix  ...  tradecount\n",
              "1                               1.64E+12  ...       17040\n",
              "2                               1.64E+12  ...       45868\n",
              "3                               1.64E+12  ...       32006\n",
              "4                               1.64E+12  ...       28574\n",
              "...                                  ...  ...         ...\n",
              "40492                         1502956800  ...         NaN\n",
              "40493                         1502953200  ...         NaN\n",
              "40494                         1502949600  ...         NaN\n",
              "40495                         1502946000  ...         NaN\n",
              "40496                         1502942400  ...         NaN\n",
              "\n",
              "[40497 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "#Useful imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import copy\n",
        "\n",
        "#Trimming and naming columns/rows\n",
        "raw = pd.read_csv(\"/content/drive/My Drive/Machine Learning/BTCUSDT Analysis/binance_BTCUSDT_1h.csv\")\n",
        "raw"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = raw.set_axis(raw.loc[0], axis=1)\n",
        "#Trim unnecessary rows and columns\n",
        "data = data.drop(0, axis=0)\n",
        "data = data.drop(\"unix\", axis=1)\n",
        "data = data.drop(\"symbol\", axis=1)\n",
        "data = data.drop(\"Volume USDT\", axis=1)\n",
        "data = data.drop(\"tradecount\", axis=1)\n",
        "\n",
        "#Make a new DataFrame for the new days and times columns\n",
        "dates = data[\"date\"]\n",
        "times = copy.copy(dates)\n",
        "days = copy.copy(dates)\n",
        "for i in range(1,40497):\n",
        "    #Split using whitespace to separate day and time\n",
        "    t_ = dates[i].split(\" \")\n",
        "    #Assign day variable\n",
        "    d_ = t_[0]\n",
        "    #Split day by year, month, and day\n",
        "    d_ = d_.split(\"-\")\n",
        "    #Assign time value\n",
        "    t_ = t_[1][0:2] + \":00\"\n",
        "    #Fixing an error -- optimize this bit later\n",
        "    if t_ == \"0::00\":\n",
        "        t_ = \"00:00\"\n",
        "    #Assign new values to columns\n",
        "    times[i] = t_\n",
        "    days[i] = d_\n",
        "#Assign columns to place in data\n",
        "data[\"YY/MM/DD\"] = days\n",
        "data[\"Time\"] = times\n",
        "#Date table is now redundant\n",
        "data = data.drop(\"date\", axis=1)\n",
        "#Weird data point, goodbye\n",
        "data = data.drop(40496)\n",
        "#Reverse table and reindex so time flows with the row index\n",
        "data = data[::-1]\n",
        "data = data.set_axis(np.arange(1,40496,1),axis=0)\n",
        "data[\"VOL\"] = data[\"Volume BTC\"]\n",
        "data = data.drop(\"Volume BTC\", axis=1)\n",
        "#Reorder columns for visual clarity\n",
        "data = data[[\"Time\", \"YY/MM/DD\", \"open\", \"close\", \"high\", \"low\", \"VOL\"]]\n",
        "data[\"high\"] = pd.to_numeric(data[\"high\"])\n",
        "data[\"low\"] = pd.to_numeric(data[\"low\"])\n",
        "data[\"open\"] = pd.to_numeric(data[\"open\"])\n",
        "data[\"close\"] = pd.to_numeric(data[\"close\"])\n",
        "data[\"VOL\"] = pd.to_numeric(data[\"VOL\"])\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "lM_G4F05oMZS",
        "outputId": "a5b862e8-9319-4e8d-e9d7-6e10d8c07350"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0745cd98-925f-483f-929d-4c7448e99490\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>YY/MM/DD</th>\n",
              "      <th>open</th>\n",
              "      <th>close</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>VOL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>05:00</td>\n",
              "      <td>[2017, 08, 17]</td>\n",
              "      <td>4308.83</td>\n",
              "      <td>4315.32</td>\n",
              "      <td>4328.69</td>\n",
              "      <td>4291.37</td>\n",
              "      <td>23.23000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>06:00</td>\n",
              "      <td>[2017, 08, 17]</td>\n",
              "      <td>4315.32</td>\n",
              "      <td>4324.35</td>\n",
              "      <td>4345.45</td>\n",
              "      <td>4309.37</td>\n",
              "      <td>7.23000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>07:00</td>\n",
              "      <td>[2017, 08, 17]</td>\n",
              "      <td>4324.35</td>\n",
              "      <td>4349.99</td>\n",
              "      <td>4349.99</td>\n",
              "      <td>4287.41</td>\n",
              "      <td>4.44000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>08:00</td>\n",
              "      <td>[2017, 08, 17]</td>\n",
              "      <td>4349.99</td>\n",
              "      <td>4360.69</td>\n",
              "      <td>4377.85</td>\n",
              "      <td>4333.32</td>\n",
              "      <td>0.94990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>09:00</td>\n",
              "      <td>[2017, 08, 17]</td>\n",
              "      <td>4360.69</td>\n",
              "      <td>4444.00</td>\n",
              "      <td>4445.78</td>\n",
              "      <td>4360.00</td>\n",
              "      <td>10.76000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40491</th>\n",
              "      <td>20:00</td>\n",
              "      <td>[2021, 12, 11]</td>\n",
              "      <td>48407.25</td>\n",
              "      <td>48564.07</td>\n",
              "      <td>48736.94</td>\n",
              "      <td>48391.68</td>\n",
              "      <td>636.46533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40492</th>\n",
              "      <td>21:00</td>\n",
              "      <td>[2021, 12, 11]</td>\n",
              "      <td>48564.06</td>\n",
              "      <td>48782.79</td>\n",
              "      <td>48839.95</td>\n",
              "      <td>48390.22</td>\n",
              "      <td>693.14915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40493</th>\n",
              "      <td>22:00</td>\n",
              "      <td>[2021, 12, 11]</td>\n",
              "      <td>48779.31</td>\n",
              "      <td>48826.36</td>\n",
              "      <td>49146.21</td>\n",
              "      <td>48628.36</td>\n",
              "      <td>821.94948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40494</th>\n",
              "      <td>23:00</td>\n",
              "      <td>[2021, 12, 11]</td>\n",
              "      <td>48826.36</td>\n",
              "      <td>49389.99</td>\n",
              "      <td>49485.71</td>\n",
              "      <td>48793.65</td>\n",
              "      <td>1303.91272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40495</th>\n",
              "      <td>00:00</td>\n",
              "      <td>[2021, 12, 12]</td>\n",
              "      <td>49389.99</td>\n",
              "      <td>49482.13</td>\n",
              "      <td>49577.00</td>\n",
              "      <td>49301.07</td>\n",
              "      <td>591.84649</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>40495 rows  7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0745cd98-925f-483f-929d-4c7448e99490')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0745cd98-925f-483f-929d-4c7448e99490 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0745cd98-925f-483f-929d-4c7448e99490');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "0       Time        YY/MM/DD      open  ...      high       low         VOL\n",
              "1      05:00  [2017, 08, 17]   4308.83  ...   4328.69   4291.37    23.23000\n",
              "2      06:00  [2017, 08, 17]   4315.32  ...   4345.45   4309.37     7.23000\n",
              "3      07:00  [2017, 08, 17]   4324.35  ...   4349.99   4287.41     4.44000\n",
              "4      08:00  [2017, 08, 17]   4349.99  ...   4377.85   4333.32     0.94990\n",
              "5      09:00  [2017, 08, 17]   4360.69  ...   4445.78   4360.00    10.76000\n",
              "...      ...             ...       ...  ...       ...       ...         ...\n",
              "40491  20:00  [2021, 12, 11]  48407.25  ...  48736.94  48391.68   636.46533\n",
              "40492  21:00  [2021, 12, 11]  48564.06  ...  48839.95  48390.22   693.14915\n",
              "40493  22:00  [2021, 12, 11]  48779.31  ...  49146.21  48628.36   821.94948\n",
              "40494  23:00  [2021, 12, 11]  48826.36  ...  49485.71  48793.65  1303.91272\n",
              "40495  00:00  [2021, 12, 12]  49389.99  ...  49577.00  49301.07   591.84649\n",
              "\n",
              "[40495 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TA Indicators\n",
        "\n",
        "Now, I need to decide on which TA indicators the algorithm will consider. Certain TAs such as moving average are an absolute necessity, as they are often used to calculate further TAs. These will be implemented as-needed for such further TAs. The first TA I wish to employ are Bollinger Bands. The Bollinger Bands use a moving average, with the standard being 20 ticks. I will use this for the algorithm."
      ],
      "metadata": {
        "id": "KdcA1Vt6pRnF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### MA and STD Functions"
      ],
      "metadata": {
        "id": "Z3vaiXr247nU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sma(items, n):\n",
        "    \"\"\"\n",
        "    get_sma() function will return the simple moving average for the list \"items\" with period \"n\".\n",
        "    \"\"\"\n",
        "    return items.rolling(n).mean()\n",
        "\n",
        "def get_std(items, n):\n",
        "    \"\"\"\n",
        "    get_std() function will return the standard deviation for the list \"items\" with period \"n\".\n",
        "    \"\"\"\n",
        "    return items.rolling(n).std()"
      ],
      "metadata": {
        "id": "CzL98ehH490y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bollinger Bands (20-day)\n",
        "Bollinger Bands are simply the moving average of a period plus and minus two standard deviation in each direction:\n",
        "$$BB = SMA + (2*STD)$$"
      ],
      "metadata": {
        "id": "7mZ6Kymp44FD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_bollinger_bands(items, n):\n",
        "    sma = get_sma(items, n)\n",
        "    std = get_std(items, n)\n",
        "    boll_up = sma + (2*std)\n",
        "    boll_dn = sma - (2*std)\n",
        "    return boll_up, boll_dn\n",
        "\n",
        "boll_up, boll_dn = get_bollinger_bands(data[\"close\"], 20)\n",
        "data[\"BB_up_20\"], data[\"BB_dn_20\"] = boll_up, boll_dn\n",
        "\n",
        "fig = plt.figure(figsize=(12,8))\n",
        "data[\"SMA_20\"] = get_sma(data[\"close\"], 20)\n",
        "data[\"SMA_50\"] = get_sma(data[\"close\"], 50)\n",
        "plt.plot(data[\"SMA_20\"][100:300],label=\"20-day MA\",color=\"Yellow\")\n",
        "plt.plot(data[\"BB_up_20\"][100:300],color=\"Red\")\n",
        "plt.plot(data[\"BB_dn_20\"][100:300],color=\"Red\",label=\"Bollinger Bands\", linewidth=2)\n",
        "plt.plot(data[\"close\"][100:300],label=\"Hourly Close Price\",color=\"Blue\", linewidth=2)\n",
        "plt.title(\"Sample plot of Bollinger Bands for 300 periods of hourly BTCUSDT\")\n",
        "plt.legend();"
      ],
      "metadata": {
        "id": "tqcLKOIy0dXb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "outputId": "0e99d603-d022-4644-a761-fae69e4106f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Average True Range (20-day)\n",
        "Average True Range considers three quantities:\n",
        "*   HL = High - Low\n",
        "*   HC = |High - Previous Close|\n",
        "*   LC = |Low - Previous Close|\n",
        "\n",
        "For each data point, keep only the maximum of the above three quantities:\n",
        "$TR_i$ = Max(HL, HC, LC). Lastly, average these quantities over the desired period.\n",
        "\n",
        "$$ATR = \\frac{1}{n}\\sum_{i=-n}^0 TR_i$$\n",
        "\n"
      ],
      "metadata": {
        "id": "rXLX2j1_wiNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_atr(High, Low, Close, n):\n",
        "    TRs = copy.copy(High)\n",
        "    for i in range(2,len(High)+1):\n",
        "        HL = High[i] - Low[i]\n",
        "        HC = abs(High[i]-Close[i-1])\n",
        "        LC = abs(Low[i]-Close[i-1])\n",
        "        TRs[i] = max(HL,HC,LC)\n",
        "    return TRs.rolling(n).mean()\n",
        "\n",
        "data[\"ATR\"] = get_atr(data[\"high\"], data[\"low\"], data[\"close\"], 20)\n",
        "data[60:70]"
      ],
      "metadata": {
        "id": "e86Y0SijrYLm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "323792fa-cb6a-4e70-82b6-2b0eb88c38f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>YY/MM/DD</th>\n",
              "      <th>open</th>\n",
              "      <th>close</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>VOL</th>\n",
              "      <th>ATR</th>\n",
              "      <th>BB_up_20</th>\n",
              "      <th>BB_dn_20</th>\n",
              "      <th>SMA_20</th>\n",
              "      <th>SMA_50</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>05:00</td>\n",
              "      <td>[2017, 08, 19]</td>\n",
              "      <td>4000.00</td>\n",
              "      <td>4027.37</td>\n",
              "      <td>4048.99</td>\n",
              "      <td>3976.72</td>\n",
              "      <td>3.0700</td>\n",
              "      <td>95.5980</td>\n",
              "      <td>4187.809865</td>\n",
              "      <td>3931.863135</td>\n",
              "      <td>4059.8365</td>\n",
              "      <td>4182.2344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>06:00</td>\n",
              "      <td>[2017, 08, 19]</td>\n",
              "      <td>4027.37</td>\n",
              "      <td>4086.29</td>\n",
              "      <td>4096.00</td>\n",
              "      <td>4013.69</td>\n",
              "      <td>16.9600</td>\n",
              "      <td>90.0605</td>\n",
              "      <td>4184.577095</td>\n",
              "      <td>3932.349905</td>\n",
              "      <td>4058.4635</td>\n",
              "      <td>4176.8766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>07:00</td>\n",
              "      <td>[2017, 08, 19]</td>\n",
              "      <td>4086.29</td>\n",
              "      <td>4076.12</td>\n",
              "      <td>4103.92</td>\n",
              "      <td>4073.47</td>\n",
              "      <td>1.6200</td>\n",
              "      <td>89.0530</td>\n",
              "      <td>4181.088570</td>\n",
              "      <td>3932.613430</td>\n",
              "      <td>4056.8510</td>\n",
              "      <td>4171.3154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>08:00</td>\n",
              "      <td>[2017, 08, 19]</td>\n",
              "      <td>4076.12</td>\n",
              "      <td>4075.98</td>\n",
              "      <td>4103.92</td>\n",
              "      <td>4051.47</td>\n",
              "      <td>2.9900</td>\n",
              "      <td>86.9740</td>\n",
              "      <td>4166.656582</td>\n",
              "      <td>3938.294418</td>\n",
              "      <td>4052.4755</td>\n",
              "      <td>4167.6956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>09:00</td>\n",
              "      <td>[2017, 08, 19]</td>\n",
              "      <td>4075.98</td>\n",
              "      <td>4074.23</td>\n",
              "      <td>4149.99</td>\n",
              "      <td>4074.23</td>\n",
              "      <td>3.9500</td>\n",
              "      <td>88.6830</td>\n",
              "      <td>4154.289777</td>\n",
              "      <td>3943.231223</td>\n",
              "      <td>4048.7605</td>\n",
              "      <td>4162.6756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>10:00</td>\n",
              "      <td>[2017, 08, 19]</td>\n",
              "      <td>4074.23</td>\n",
              "      <td>4139.98</td>\n",
              "      <td>4141.00</td>\n",
              "      <td>4074.23</td>\n",
              "      <td>2.3600</td>\n",
              "      <td>90.2480</td>\n",
              "      <td>4150.148721</td>\n",
              "      <td>3945.731279</td>\n",
              "      <td>4047.9400</td>\n",
              "      <td>4158.9706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>11:00</td>\n",
              "      <td>[2017, 08, 19]</td>\n",
              "      <td>4139.98</td>\n",
              "      <td>4139.98</td>\n",
              "      <td>4139.98</td>\n",
              "      <td>4120.78</td>\n",
              "      <td>0.0527</td>\n",
              "      <td>87.3840</td>\n",
              "      <td>4150.488758</td>\n",
              "      <td>3945.534242</td>\n",
              "      <td>4048.0115</td>\n",
              "      <td>4155.0992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>12:00</td>\n",
              "      <td>[2017, 08, 20]</td>\n",
              "      <td>4139.98</td>\n",
              "      <td>4086.09</td>\n",
              "      <td>4139.98</td>\n",
              "      <td>4044.00</td>\n",
              "      <td>2.3400</td>\n",
              "      <td>86.6960</td>\n",
              "      <td>4152.426829</td>\n",
              "      <td>3945.379171</td>\n",
              "      <td>4048.9030</td>\n",
              "      <td>4150.0850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>01:00</td>\n",
              "      <td>[2017, 08, 20]</td>\n",
              "      <td>4086.09</td>\n",
              "      <td>4082.53</td>\n",
              "      <td>4086.09</td>\n",
              "      <td>4052.82</td>\n",
              "      <td>1.0600</td>\n",
              "      <td>83.5535</td>\n",
              "      <td>4153.048268</td>\n",
              "      <td>3945.310732</td>\n",
              "      <td>4049.1795</td>\n",
              "      <td>4146.0340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>02:00</td>\n",
              "      <td>[2017, 08, 20]</td>\n",
              "      <td>4082.53</td>\n",
              "      <td>4124.69</td>\n",
              "      <td>4124.69</td>\n",
              "      <td>4082.53</td>\n",
              "      <td>2.3700</td>\n",
              "      <td>80.9050</td>\n",
              "      <td>4160.816879</td>\n",
              "      <td>3951.324121</td>\n",
              "      <td>4056.0705</td>\n",
              "      <td>4142.7972</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "0    Time        YY/MM/DD     open  ...     BB_dn_20     SMA_20     SMA_50\n",
              "61  05:00  [2017, 08, 19]  4000.00  ...  3931.863135  4059.8365  4182.2344\n",
              "62  06:00  [2017, 08, 19]  4027.37  ...  3932.349905  4058.4635  4176.8766\n",
              "63  07:00  [2017, 08, 19]  4086.29  ...  3932.613430  4056.8510  4171.3154\n",
              "64  08:00  [2017, 08, 19]  4076.12  ...  3938.294418  4052.4755  4167.6956\n",
              "65  09:00  [2017, 08, 19]  4075.98  ...  3943.231223  4048.7605  4162.6756\n",
              "66  10:00  [2017, 08, 19]  4074.23  ...  3945.731279  4047.9400  4158.9706\n",
              "67  11:00  [2017, 08, 19]  4139.98  ...  3945.534242  4048.0115  4155.0992\n",
              "68  12:00  [2017, 08, 20]  4139.98  ...  3945.379171  4048.9030  4150.0850\n",
              "69  01:00  [2017, 08, 20]  4086.09  ...  3945.310732  4049.1795  4146.0340\n",
              "70  02:00  [2017, 08, 20]  4082.53  ...  3951.324121  4056.0705  4142.7972\n",
              "\n",
              "[10 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deep Learning Approach\n"
      ],
      "metadata": {
        "id": "YzcnADvimUkw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The above is nice and fancy and all, but I never really took the time to research what algorithms I should use. A deep learning network seems intuitive, since this is a complex problem and I would like some flexibility with the algorithm that a strict regression or classification algorithm cannot supply.\n",
        "\n",
        "I also believe that I should focus on a few high quality indicators, rather than many many constructed indicators. Of course, when creating the final product, I will let the numbers decide which indicators I should use. For the time being, I will simply use a few standard deviation and moving average indicators.\n",
        "\n",
        "\n",
        "### The Grader Function\n",
        "\n",
        "The cornerstone of this approach is the grader function in the code block below. This is a compromise to label the data, since ideally the algorithm would be able to place both long and short orders, as well as vary the amount placed on each trade. However, I do not know of a way to allow the network to calculate the true value of a label during the training, as would be required for such a flexible algorithm.\n",
        "\n",
        "Instead, I train the algorithm to always place long trades with specified stop-loss (SL) and take-profit (TP) levels. These levels are decided based on the following variables:\n",
        "\n",
        "*    Reward/risk ratio: The reward to risk ratio is the ratio of potential profit to the potential loss.\n",
        "*    Profit level: The desired TP level for the trade, in terms of percentage increase.\n",
        "\n",
        "Both the reward to risk ratio and the profit level need to be specified to the grader function. The last missing piece is the amount of data points to check for the specified TP/SL levels. Of course, I could let the algorithm go on forever until either the TP or SL is triggered, but since the algorithm is designed to work on short timescales, I should limit the grader function to work in this scope.\n",
        "\n",
        "With all these variables, the grader function executes as follows. Given the arguments:\n",
        "* df     : A dataframe of shape (1,X) with all the closing prices is sent to the function.\n",
        "* profit : The desired profit percentage on the trade\n",
        "* rr     :The desired reward to risk ratio\n",
        "* n      :The amount of data points to check\n",
        "\n",
        "For every data point in 'df', the function will iterate over the next 'n' data points immediately following the current data point d[i]. If at any point d[i] exceeds the TP level (1+profit) or falls below the SL level (1-$profit/rr) then the current loop iteration will break and return 1 or 0. A 1 corresponds to a successful trade, and a 0 represents a failed trade."
      ],
      "metadata": {
        "id": "N8OepGaIxxO2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Useful imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import copy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "def get_sma(items, n):\n",
        "    \"\"\"\n",
        "    get_sma() function will return the simple moving average for the list \"items\" with period \"n\".\n",
        "    \"\"\"\n",
        "    return items.rolling(n).mean()\n",
        "\n",
        "def get_std(items, n):\n",
        "    \"\"\"\n",
        "    get_std() function will return the standard deviation for the list \"items\" with period \"n\".\n",
        "    \"\"\"\n",
        "    return items.rolling(n).std()\n",
        "\n",
        "def normalize(df):\n",
        "    return (df-df.min())/(df.max()-df.min())\n",
        "\n",
        "def grader(df, profit=0.03, rr = 2, n = 40):\n",
        "    \"\"\"\n",
        "    Grader function, takes a pd DataFrame 'df' as input and outputs whether or not a buy\n",
        "        at the current data point would trigger a stop loss or a take profit within\n",
        "        'n' data points at a reward/risk ratio of 'rr.\n",
        "        df      :  pandas DataFrame with shape (1,x)\n",
        "        profit  :  The desired profit, in percentage form\n",
        "        rr      :  The reward/risk ratio, used to calculate stop-loss and take-profit\n",
        "        n       :  The number of data points to look into the future for the SL or TP.\n",
        "    \"\"\"\n",
        "    #rr is reward/risk ratio\n",
        "    sl = copy.copy(df) * (1-profit/rr)\n",
        "    tp = copy.copy(df) * (1+profit)\n",
        "\n",
        "    for i, buy in enumerate(df):\n",
        "\n",
        "        if i==df.shape[0] - n:\n",
        "            df.iloc[-n:] = 0\n",
        "\n",
        "        for k in range(i, i+n):\n",
        "            #SL Trigger\n",
        "            if buy <= sl.iloc[k]:\n",
        "                df.iloc[i] = 0\n",
        "                break\n",
        "            #TP Trigger\n",
        "            elif buy >= tp.iloc[k]:\n",
        "                df.iloc[i] = 1\n",
        "                break\n",
        "            df.iloc[i] = 0\n",
        "    return df"
      ],
      "metadata": {
        "id": "3F0q4o-Qmxki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw = pd.read_csv(\"/content/drive/MyDrive/Machine Learning/BTCUSDT Analysis/binance_BTCUSDT_1h.csv\")\n",
        "data = raw.set_axis(raw.loc[0], axis=1)\n",
        "\n",
        "#Trim unnecessary rows and columns\n",
        "data = data.drop(0, axis=0)\n",
        "data = data.drop(\"unix\", axis=1)\n",
        "data = data.drop(\"symbol\", axis=1)\n",
        "data = data.drop(\"Volume USDT\", axis=1)\n",
        "data = data.drop(\"tradecount\", axis=1)\n",
        "\n",
        "#Make a new DataFrame for the new days and times columns\n",
        "dates = data[\"date\"]\n",
        "times = copy.copy(dates)\n",
        "days = copy.copy(dates)\n",
        "for i in range(1,40497):\n",
        "    #Split using whitespace to separate day and time\n",
        "    t_ = dates[i].split(\" \")\n",
        "    #Assign day variable\n",
        "    d_ = t_[0]\n",
        "    #Split day by year, month, and day\n",
        "    d_ = d_.split(\"-\")\n",
        "    #Assign time value\n",
        "    t_ = t_[1][0:2] + \":00\"\n",
        "    #Fixing an error -- optimize this bit later\n",
        "    if t_ == \"0::00\":\n",
        "        t_ = \"00:00\"\n",
        "    #Assign new values to columns\n",
        "    times[i] = t_\n",
        "    days[i] = d_\n",
        "#Assign columns to place in data\n",
        "data[\"YY/MM/DD\"] = days\n",
        "data[\"Time\"] = times\n",
        "#Date table is now redundant\n",
        "data = data.drop(\"date\", axis=1)\n",
        "#Weird data point, goodbye\n",
        "data = data.drop(40496)\n",
        "#Reverse table and reindex so time flows with the row index\n",
        "data = data[::-1]\n",
        "data = data.set_axis(np.arange(1,40496,1),axis=0)\n",
        "data[\"VOL\"] = data[\"Volume BTC\"]\n",
        "data = data.drop(\"Volume BTC\", axis=1)\n",
        "#Reorder columns for visual clarity\n",
        "data = data[[\"Time\", \"YY/MM/DD\", \"open\", \"close\", \"high\", \"low\", \"VOL\"]]\n",
        "data[\"high\"] = pd.to_numeric(data[\"high\"])\n",
        "data[\"low\"] = pd.to_numeric(data[\"low\"])\n",
        "data[\"open\"] = pd.to_numeric(data[\"open\"])\n",
        "data[\"close\"] = pd.to_numeric(data[\"close\"])\n",
        "data[\"VOL\"] = pd.to_numeric(data[\"VOL\"])\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "o4qbjRSKnTKK",
        "outputId": "4af8eb9f-c559-4e4a-8a08-983dcad99a04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-bf2213ad-04fb-471b-b650-c01eeb845838\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>YY/MM/DD</th>\n",
              "      <th>open</th>\n",
              "      <th>close</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>VOL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>05:00</td>\n",
              "      <td>[2017, 08, 17]</td>\n",
              "      <td>4308.83</td>\n",
              "      <td>4315.32</td>\n",
              "      <td>4328.69</td>\n",
              "      <td>4291.37</td>\n",
              "      <td>23.23000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>06:00</td>\n",
              "      <td>[2017, 08, 17]</td>\n",
              "      <td>4315.32</td>\n",
              "      <td>4324.35</td>\n",
              "      <td>4345.45</td>\n",
              "      <td>4309.37</td>\n",
              "      <td>7.23000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>07:00</td>\n",
              "      <td>[2017, 08, 17]</td>\n",
              "      <td>4324.35</td>\n",
              "      <td>4349.99</td>\n",
              "      <td>4349.99</td>\n",
              "      <td>4287.41</td>\n",
              "      <td>4.44000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>08:00</td>\n",
              "      <td>[2017, 08, 17]</td>\n",
              "      <td>4349.99</td>\n",
              "      <td>4360.69</td>\n",
              "      <td>4377.85</td>\n",
              "      <td>4333.32</td>\n",
              "      <td>0.94990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>09:00</td>\n",
              "      <td>[2017, 08, 17]</td>\n",
              "      <td>4360.69</td>\n",
              "      <td>4444.00</td>\n",
              "      <td>4445.78</td>\n",
              "      <td>4360.00</td>\n",
              "      <td>10.76000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40491</th>\n",
              "      <td>20:00</td>\n",
              "      <td>[2021, 12, 11]</td>\n",
              "      <td>48407.25</td>\n",
              "      <td>48564.07</td>\n",
              "      <td>48736.94</td>\n",
              "      <td>48391.68</td>\n",
              "      <td>636.46533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40492</th>\n",
              "      <td>21:00</td>\n",
              "      <td>[2021, 12, 11]</td>\n",
              "      <td>48564.06</td>\n",
              "      <td>48782.79</td>\n",
              "      <td>48839.95</td>\n",
              "      <td>48390.22</td>\n",
              "      <td>693.14915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40493</th>\n",
              "      <td>22:00</td>\n",
              "      <td>[2021, 12, 11]</td>\n",
              "      <td>48779.31</td>\n",
              "      <td>48826.36</td>\n",
              "      <td>49146.21</td>\n",
              "      <td>48628.36</td>\n",
              "      <td>821.94948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40494</th>\n",
              "      <td>23:00</td>\n",
              "      <td>[2021, 12, 11]</td>\n",
              "      <td>48826.36</td>\n",
              "      <td>49389.99</td>\n",
              "      <td>49485.71</td>\n",
              "      <td>48793.65</td>\n",
              "      <td>1303.91272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40495</th>\n",
              "      <td>00:00</td>\n",
              "      <td>[2021, 12, 12]</td>\n",
              "      <td>49389.99</td>\n",
              "      <td>49482.13</td>\n",
              "      <td>49577.00</td>\n",
              "      <td>49301.07</td>\n",
              "      <td>591.84649</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>40495 rows  7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bf2213ad-04fb-471b-b650-c01eeb845838')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bf2213ad-04fb-471b-b650-c01eeb845838 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bf2213ad-04fb-471b-b650-c01eeb845838');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "0       Time        YY/MM/DD      open  ...      high       low         VOL\n",
              "1      05:00  [2017, 08, 17]   4308.83  ...   4328.69   4291.37    23.23000\n",
              "2      06:00  [2017, 08, 17]   4315.32  ...   4345.45   4309.37     7.23000\n",
              "3      07:00  [2017, 08, 17]   4324.35  ...   4349.99   4287.41     4.44000\n",
              "4      08:00  [2017, 08, 17]   4349.99  ...   4377.85   4333.32     0.94990\n",
              "5      09:00  [2017, 08, 17]   4360.69  ...   4445.78   4360.00    10.76000\n",
              "...      ...             ...       ...  ...       ...       ...         ...\n",
              "40491  20:00  [2021, 12, 11]  48407.25  ...  48736.94  48391.68   636.46533\n",
              "40492  21:00  [2021, 12, 11]  48564.06  ...  48839.95  48390.22   693.14915\n",
              "40493  22:00  [2021, 12, 11]  48779.31  ...  49146.21  48628.36   821.94948\n",
              "40494  23:00  [2021, 12, 11]  48826.36  ...  49485.71  48793.65  1303.91272\n",
              "40495  00:00  [2021, 12, 12]  49389.99  ...  49577.00  49301.07   591.84649\n",
              "\n",
              "[40495 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trim = pd.DataFrame([])\n",
        "trim[\"margin\"] = normalize(data[\"high\"] - data[\"low\"])[12040:]\n",
        "trim[\"movement\"] = normalize(data[\"open\"] - data[\"close\"])[12040:]\n",
        "trim[\"close\"] = normalize(data[\"close\"])\n",
        "trim[\"vol\"] = normalize(data[\"VOL\"])\n",
        "trim[\"bb_up_20\"], trim[\"bb_down_20\"] = get_bollinger_bands(trim[\"close\"], 20)\n",
        "trim[\"sma_20\"] = get_sma(trim[\"close\"], 20)\n",
        "trim[\"sd_20\"] = get_std(trim[\"close\"], 20)\n",
        "trim[\"results\"] = grader(copy.copy(trim[\"close\"]), profit=0.005, rr=2)\n",
        "\n",
        "i=0\n",
        "for item in trim[\"results\"]:\n",
        "    if item == 1:\n",
        "        i+=1\n",
        "print(i)\n",
        "\n",
        "trim = trim.iloc[20:-20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "iPENGK4XwO69",
        "outputId": "78c83841-6715-480e-dc43-f520a39e1e89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-322608849bfa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"close\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"close\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"vol\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"VOL\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"bb_up_20\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"bb_down_20\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_bollinger_bands\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"close\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtrim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sma_20\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_sma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"close\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtrim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sd_20\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_std\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"close\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'get_bollinger_bands' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trim_train, trim_test = train_test_split(trim, test_size=0.2)\n",
        "trim_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "pQ3n23mfHA2h",
        "outputId": "1e99f164-83b9-4487-f427-5a65f910730f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-06505b18-362e-4ad2-a05c-3c30efd7672b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>margin</th>\n",
              "      <th>movement</th>\n",
              "      <th>close</th>\n",
              "      <th>vol</th>\n",
              "      <th>bb_up_20</th>\n",
              "      <th>bb_down_20</th>\n",
              "      <th>sma_20</th>\n",
              "      <th>sd_20</th>\n",
              "      <th>results</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>33646</th>\n",
              "      <td>0.039382</td>\n",
              "      <td>0.521948</td>\n",
              "      <td>0.660695</td>\n",
              "      <td>0.041695</td>\n",
              "      <td>0.667936</td>\n",
              "      <td>0.608875</td>\n",
              "      <td>0.638405</td>\n",
              "      <td>0.014765</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36198</th>\n",
              "      <td>0.077111</td>\n",
              "      <td>0.444791</td>\n",
              "      <td>0.574970</td>\n",
              "      <td>0.099599</td>\n",
              "      <td>0.575051</td>\n",
              "      <td>0.560207</td>\n",
              "      <td>0.567629</td>\n",
              "      <td>0.003711</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27163</th>\n",
              "      <td>0.029784</td>\n",
              "      <td>0.505658</td>\n",
              "      <td>0.129070</td>\n",
              "      <td>0.189578</td>\n",
              "      <td>0.129549</td>\n",
              "      <td>0.127716</td>\n",
              "      <td>0.128632</td>\n",
              "      <td>0.000458</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38451</th>\n",
              "      <td>0.068237</td>\n",
              "      <td>0.518541</td>\n",
              "      <td>0.673769</td>\n",
              "      <td>0.065304</td>\n",
              "      <td>0.689401</td>\n",
              "      <td>0.672094</td>\n",
              "      <td>0.680748</td>\n",
              "      <td>0.004327</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21067</th>\n",
              "      <td>0.005306</td>\n",
              "      <td>0.512331</td>\n",
              "      <td>0.078709</td>\n",
              "      <td>0.019214</td>\n",
              "      <td>0.080166</td>\n",
              "      <td>0.077372</td>\n",
              "      <td>0.078769</td>\n",
              "      <td>0.000698</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14383</th>\n",
              "      <td>0.003055</td>\n",
              "      <td>0.511468</td>\n",
              "      <td>0.034578</td>\n",
              "      <td>0.034441</td>\n",
              "      <td>0.036213</td>\n",
              "      <td>0.032756</td>\n",
              "      <td>0.034484</td>\n",
              "      <td>0.000864</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29084</th>\n",
              "      <td>0.005531</td>\n",
              "      <td>0.514836</td>\n",
              "      <td>0.118047</td>\n",
              "      <td>0.041631</td>\n",
              "      <td>0.119619</td>\n",
              "      <td>0.117888</td>\n",
              "      <td>0.118753</td>\n",
              "      <td>0.000433</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40360</th>\n",
              "      <td>0.143765</td>\n",
              "      <td>0.606142</td>\n",
              "      <td>0.677309</td>\n",
              "      <td>0.087864</td>\n",
              "      <td>0.712025</td>\n",
              "      <td>0.681983</td>\n",
              "      <td>0.697004</td>\n",
              "      <td>0.007510</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40432</th>\n",
              "      <td>0.075198</td>\n",
              "      <td>0.551091</td>\n",
              "      <td>0.704378</td>\n",
              "      <td>0.042673</td>\n",
              "      <td>0.732461</td>\n",
              "      <td>0.704910</td>\n",
              "      <td>0.718685</td>\n",
              "      <td>0.006888</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24850</th>\n",
              "      <td>0.003578</td>\n",
              "      <td>0.511902</td>\n",
              "      <td>0.098653</td>\n",
              "      <td>0.037862</td>\n",
              "      <td>0.100781</td>\n",
              "      <td>0.098205</td>\n",
              "      <td>0.099493</td>\n",
              "      <td>0.000644</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>22732 rows  9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-06505b18-362e-4ad2-a05c-3c30efd7672b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-06505b18-362e-4ad2-a05c-3c30efd7672b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-06505b18-362e-4ad2-a05c-3c30efd7672b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         margin  movement     close  ...    sma_20     sd_20  results\n",
              "33646  0.039382  0.521948  0.660695  ...  0.638405  0.014765      0.0\n",
              "36198  0.077111  0.444791  0.574970  ...  0.567629  0.003711      1.0\n",
              "27163  0.029784  0.505658  0.129070  ...  0.128632  0.000458      1.0\n",
              "38451  0.068237  0.518541  0.673769  ...  0.680748  0.004327      0.0\n",
              "21067  0.005306  0.512331  0.078709  ...  0.078769  0.000698      0.0\n",
              "...         ...       ...       ...  ...       ...       ...      ...\n",
              "14383  0.003055  0.511468  0.034578  ...  0.034484  0.000864      1.0\n",
              "29084  0.005531  0.514836  0.118047  ...  0.118753  0.000433      0.0\n",
              "40360  0.143765  0.606142  0.677309  ...  0.697004  0.007510      0.0\n",
              "40432  0.075198  0.551091  0.704378  ...  0.718685  0.006888      0.0\n",
              "24850  0.003578  0.511902  0.098653  ...  0.099493  0.000644      1.0\n",
              "\n",
              "[22732 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data is in\n",
        "\n",
        "Now gotta iterate over different combinations of MA and ST.DEV.. I think now is the time to create the framework for the model so I can start iterating over different combinations."
      ],
      "metadata": {
        "id": "div9m6sCntVT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Here's the prototype model architecture\n",
        "model = tf.keras.Sequential()\n",
        "model.add(Dense(18, input_dim=trim_train.shape[1]-1, activation='relu'))\n",
        "model.add(Dense(9, activation='relu'))\n",
        "model.add(Dense(1, activation='softmax'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(trim_train.iloc[:,:-1], trim_train.iloc[:,-1], epochs=3, batch_size=16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcMbYIwknUUp",
        "outputId": "7b74e21e-1220-40c4-8cef-b30cd6788de1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "1421/1421 [==============================] - 5s 3ms/step - loss: 0.6782 - accuracy: 0.4086\n",
            "Epoch 2/3\n",
            "1421/1421 [==============================] - 5s 3ms/step - loss: 0.6761 - accuracy: 0.4086\n",
            "Epoch 3/3\n",
            "1421/1421 [==============================] - 5s 3ms/step - loss: 0.6761 - accuracy: 0.4086\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3ff5588ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(trim_test.iloc[:,:-1])\n",
        "confusion_matrix(trim_test[\"results\"], y_pred)"
      ],
      "metadata": {
        "id": "dvQ4XTM35BWT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e7cae2d-7520-40c5-d319-66b3d2f7bcad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0, 3329],\n",
              "       [   0, 2354]])"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clearly this is trash\n",
        "\n",
        "It's obvious that this approach will likely not work, and the missing component is that the network is looking at isolated data points, when context is extremely important for analyzing price of BTC. Instead, an algorithm such as an LSTM layer would be much better suited for this problem. In the next section I will use a minute chart instead of hourly, as well as implement some new algorithms that encorporate previous information."
      ],
      "metadata": {
        "id": "oMJuJsfaxlUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Key Points\n",
        "An algorithm that is able to use the context of the chart is necessary for the success of the project. I do not want to lose the flexibility of the deep-learning framework, and so this leads directly to using RNN layers in the training of the model. Based on what I've learned from the previous sections, these are some of the key points for implementing this new version:"
      ],
      "metadata": {
        "id": "O_T-vpuaCubN"
      }
    }
  ]
}